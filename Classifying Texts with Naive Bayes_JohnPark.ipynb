{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea99549e",
   "metadata": {},
   "source": [
    "John Park (UBID: 50285417)\n",
    "\n",
    "MTH 448\n",
    "\n",
    "Apr. 23, 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1aef771",
   "metadata": {},
   "source": [
    "# Classifying Texts with Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f4378e",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a7c44e6",
   "metadata": {},
   "source": [
    "In the realm of natural language processing, text classification is a fundamental task with a wide range of applications, including sentiment analysis, topic identification, and spam detection. Naive Bayes is a simple and efficient probabilistic machine learning algorithm. It plays significant role for text classification tasks with its ease of implementation and strong performance in many real-world scenarios. This project aims to investigate the Naive Bayes classifier by appling it to two distinct datasets for text classification: (1) newsgroup posts and (2) movie reviews."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c82ed7a",
   "metadata": {},
   "source": [
    "The main goal is to assess naive bayes classifier's ability to predict the newsgroup to which a post belongs and the sentiment of a movie review. This study will not only evaluate the classification accuracy but also delve into the finer aspects of the algorithm, such as the impact of stopwords on the performance and the role of the training set size. The most frequent words in each class of texts and misclassified examples will be analyzed as well. To ensure a thorough understanding of the Naive Bayes classifier, this project implement it from scratch, without relying on pre-built machine learning libraries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b5cdc3",
   "metadata": {},
   "source": [
    "Overall the whole project aims to provide valuable insights into the capabilities and limitations of the Naive Bayes classifier for text classification alongside, practical recommendations to improve its performance for various applications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79161431",
   "metadata": {},
   "source": [
    "The first approach is importing essential libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 773,
   "id": "ccb6deca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%pylab is deprecated, use %matplotlib inline and import the required libraries.\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from zipfile import ZipFile\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import defaultdict, Counter\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5cc5f4e",
   "metadata": {},
   "source": [
    "Then, in order to analyze, both datasets should be cleared so that they only consist of proper words, which affect the meanings and contexts of the news posts and reviews. Unnecessary strings may hinder the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1053,
   "id": "f1bce945",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clearing Strings of Text\n",
    "def clean_string(string):    \n",
    "# Unnecessary strings from the text\n",
    "    bad_strings = ['<br','\\n','.',',',';','>','/']\n",
    "    for bad in bad_strings:\n",
    "# Removing unncessary strings by changing it to empty string ''\n",
    "        string = string.replace(bad,'')\n",
    "# Remove '-' and Double Space into ' '  \n",
    "    string = string.replace('-',' ').replace('  ',' ')\n",
    "    return string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a32368c",
   "metadata": {},
   "source": [
    "## Part 1. News Group"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00cc4052",
   "metadata": {},
   "source": [
    "The first part of the project is investigating Newsgroup. The first step is Load and Preprocess the Data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f33132d2",
   "metadata": {},
   "source": [
    "### Load and Preprocess the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 959,
   "id": "d7933426",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load newsgroups.zip\n",
    "with ZipFile(\"newsgroups.zip\", 'r') as zipped:\n",
    "    txt = zipped.read('newsgroups.txt').decode(encoding='utf8', errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1058,
   "id": "09e6b258",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       >sure sounds like they got a ringer.  the 325i...\n",
       "1       I have been hearing bad thing about amalgam de...\n",
       "2       >DATE:   Tue, 6 Apr 1993 00:11:49 GMT\\n>FROM: ...\n",
       "3       In article <1993Apr16.174843.28111@cabell.vcu....\n",
       "4       In article <visser.735284180@convex.convex.com...\n",
       "                              ...                        \n",
       "7373    L(>  levin@bbn.com (Joel B Levin) writes:\\nL(>...\n",
       "7374    In article <1r3sbbINN8e0@hp-col.col.hp.com>, t...\n",
       "7375    \\nWell, since someone probably wanted to know,...\n",
       "7376    \\nHello Hockey fans.\\nBonjour tout le monde!\\n...\n",
       "7377    If the Islanders beat the Devils tonight, they...\n",
       "Name: Body, Length: 7378, dtype: object"
      ]
     },
     "execution_count": 1058,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split txt files by each post\n",
    "entries = txt.split('Newsgroup: ')[1:]\n",
    "# Make empty list to store new Data\n",
    "data = []\n",
    "# Loop through all posts\n",
    "for post in entries:\n",
    "# Split the post into each line\n",
    "    lines = post.strip().split('\\n')\n",
    "# Name of Newsgroup of post is first item in array\n",
    "    newsgroup = lines[0].split(' ')[0]\n",
    "# Main post\n",
    "    post_text = '\\n'.join(lines[5:])\n",
    "# Append to data and each list contains two dictionaries in it\n",
    "    data.append({'Newsgroup': newsgroup, 'Body': post_text})\n",
    "news_df = pd.DataFrame(data)\n",
    "news_df['Body']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1060,
   "id": "fc8ced76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the data\n",
    "def preprocess(text):\n",
    "# Make all lowercase\n",
    "    text = text.lower()\n",
    "# Clean bad strings of the text\n",
    "    text = clean_string(text)\n",
    "# Remove non-alphanumeric characters and replace them with ' '\n",
    "    text = re.sub(r'\\W+', ' ', text)\n",
    "# Split them into a list of individual words\n",
    "    words = text.split()\n",
    "# Return new list\n",
    "    return words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d3d15b",
   "metadata": {},
   "source": [
    "After preporcessing, the next step is spliting data into training and testing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d77645",
   "metadata": {},
   "source": [
    "### Split Data into Training and Testing Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 962,
   "id": "5bb46075",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing sets\n",
    "data_train, data_test = train_test_split(news_df, test_size=0.1, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 963,
   "id": "88b9f028",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sci.med               905\n",
       "rec.sport.hockey      895\n",
       "rec.sport.baseball    893\n",
       "rec.motorcycles       893\n",
       "sci.electronics       887\n",
       "rec.autos             885\n",
       "alt.atheism           714\n",
       "talk.religion.misc    568\n",
       "Name: Newsgroup, dtype: int64"
      ]
     },
     "execution_count": 963,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Name of Newsgroups and Number of Posts from each group in Training Set\n",
    "data_train['Newsgroup'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 964,
   "id": "dfd23819",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7321    \\n\\tThis comes indirectly from Al Morgani who ...\n",
       "3420    Tall Cool One (rky57514@uxa.cso.uiuc.edu) wrot...\n",
       "3531    Andy Collins (acollins@uclink.berkeley.edu) wr...\n",
       "2812    \\n    I hope that this comes off as a somewhat...\n",
       "3913    Reading all you folks things to do to illegall...\n",
       "                              ...                        \n",
       "905     \\nThey detect the oscillator operating in the ...\n",
       "5192    \\nIn article <1993Apr12.201056.20753@ns1.cc.le...\n",
       "3980    In article <Apr16.215151.28035@engr.washington...\n",
       "235     In article <1993Apr6.170330.12314@is.morgan.co...\n",
       "5157    Anybody got any good/bad experience with selli...\n",
       "Name: Body, Length: 6640, dtype: object"
      ]
     },
     "execution_count": 964,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 'Body' before going into preprocess\n",
    "data_train['Body']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 965,
   "id": "c77166ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing 'Body'\n",
    "data_train['Body'] = data_train['Body'].apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 966,
   "id": "9adbd033",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7321    [this, comes, indirectly, from, al, morgani, w...\n",
       "3420    [tall, cool, one, rky57514, uxacsouiucedu, wro...\n",
       "3531    [andy, collins, acollins, uclinkberkeleyedu, w...\n",
       "2812    [i, hope, that, this, comes, off, as, a, somew...\n",
       "3913    [reading, all, you, folks, things, to, do, to,...\n",
       "                              ...                        \n",
       "905     [they, detect, the, oscillator, operating, in,...\n",
       "5192    [in, article, 1993apr1220105620753, ns1cclehig...\n",
       "3980    [in, article, apr1621515128035, engrwashington...\n",
       "235     [in, article, 1993apr617033012314, ismorgancom...\n",
       "5157    [anybody, got, any, goodbad, experience, with,...\n",
       "Name: Body, Length: 6640, dtype: object"
      ]
     },
     "execution_count": 966,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 'Body' after preprocess\n",
    "data_train['Body']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c0461ec",
   "metadata": {},
   "source": [
    "Using preprocessed trained data, this is the main part, implementing the Naive Bayes classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "296c0dd0",
   "metadata": {},
   "source": [
    "### Implement the Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d55c397",
   "metadata": {},
   "source": [
    "The first step of implementing the Naive Bayes classifier is calculating prior probabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff233ac",
   "metadata": {},
   "source": [
    "The prior probabilities represent the general frequency of each newsgroup in the dataset. This information helps the classifier make an initial guess about the newsgroup of a given post. It plays an essential role by providing a baseline for comparison when evaluating the likelihoods of words in a given post."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1062,
   "id": "c90d1eb3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sci.med               0.136295\n",
       "rec.sport.hockey      0.134789\n",
       "rec.sport.baseball    0.134488\n",
       "rec.motorcycles       0.134488\n",
       "sci.electronics       0.133584\n",
       "rec.autos             0.133283\n",
       "alt.atheism           0.107530\n",
       "talk.religion.misc    0.085542\n",
       "Name: Newsgroup, dtype: float64"
      ]
     },
     "execution_count": 1062,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate prior probabilities\n",
    "# Measure the count of each newsgroup in the training dataset\n",
    "newsgroup_counts = data_train['Newsgroup'].value_counts()\n",
    "# Divide each count by the length of the training dataset\n",
    "prior_probs = newsgroup_counts / len(data_train)\n",
    "prior_probs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0858275",
   "metadata": {},
   "source": [
    "Next step is calculating likelihoods of each word in each newsgroup."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e3ea36",
   "metadata": {},
   "source": [
    "The likelihood of each word in each newsgroup helps the classifier understand the relationship between words and newsgroups. It measures the probability of observing a particular word in a given newsgroup, which is essential for determining the probability of a post belonging to a specific newsgroup based on its content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1063,
   "id": "a2b6363b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate word counts for each newsgroup\n",
    "# Initialize a dictionary with a default value of a Counter\n",
    "word_like_news = defaultdict(Counter)\n",
    "# Loop through all posts of each group in training dataset \n",
    "for newsgroup, texts in data_train.groupby('Newsgroup'):\n",
    "# Loop through each post\n",
    "    for text in texts['Body']:\n",
    "# Loop through each word of the post\n",
    "        for word in text:\n",
    "# The dictionary stores the word frequency for each newsgroup\n",
    "            word_like_news[newsgroup][word] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9592ca5",
   "metadata": {},
   "source": [
    "Now, this step is classifying the newsgroup of posts of testing dataset using likelihoods of words in each newsgroup. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1067,
   "id": "4c667801",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify a new post\n",
    "def classify_post(post):\n",
    "# preprocess new post\n",
    "    post_words = preprocess(post)\n",
    "# Empty dictionary for storing \n",
    "    newsgroup_probs = {}\n",
    "    for newsgroup, word_count in word_like_news.items():\n",
    "        prob = np.log(prior_probs[newsgroup])\n",
    "        total_wc = sum(word_count.values())\n",
    "        for word in post_words:\n",
    "# Add 1 to word count in case that word count is 0\n",
    "# Since log(0) is Mathematically undefined, 1 is added to every word count\n",
    "            prob += np.log((word_count[word] + 1) / (len(total_wc) + len(word_count)))\n",
    "# Add to dictionary; key is Newsgroup, values is prob calculated\n",
    "        newsgroup_probs[newsgroup] = prob\n",
    "# return max(zip(newsgroup_probs.values(), newsgroup_probs.keys()))[1]\n",
    "    return max(newsgroup_probs, key=newsgroup_probs.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 970,
   "id": "559469ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply classifying method on posts of testing dataset\n",
    "news_pred = data_test['Body'].apply(classify_post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1064,
   "id": "aa368a15",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5748       rec.motorcycles\n",
       "4875           alt.atheism\n",
       "4537       sci.electronics\n",
       "5857           alt.atheism\n",
       "6721    rec.sport.baseball\n",
       "               ...        \n",
       "4980       rec.motorcycles\n",
       "6556               sci.med\n",
       "1282       sci.electronics\n",
       "2921               sci.med\n",
       "3979       sci.electronics\n",
       "Name: Body, Length: 738, dtype: object"
      ]
     },
     "execution_count": 1064,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The result predicted by classifier\n",
    "news_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a846742b",
   "metadata": {},
   "source": [
    "### Evaluate the Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d14e3bd",
   "metadata": {},
   "source": [
    "#### Does the Size of Training Set Matters?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0559247d",
   "metadata": {},
   "source": [
    "The code below calculates the accuracy of the classifier when the training size is 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1065,
   "id": "891b96cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9186991869918699"
      ]
     },
     "execution_count": 1065,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare the predicted result to the original\n",
    "newsTF_result = (news_pred == data_test['Newsgroup'])\n",
    "# Calculate the accuracy\n",
    "news_acc_09 = newsTF_result.sum() / len(data_test['Newsgroup'])\n",
    "news_acc_09"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0bea642",
   "metadata": {},
   "source": [
    "Using the codes above, by adjusting the size of testing set from the part of preprocessing the data, the investigation is led in order to study if the sizes of training set and testing set matter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e728f67e",
   "metadata": {},
   "source": [
    "|Train Size|Test Size|Accuracy|\n",
    "|-|-|-|\n",
    "|0.1|0.9|0.7067|\n",
    "|0.3|0.7|0.8426|\n",
    "|0.5|0.5|0.8702|\n",
    "|0.7|0.3|0.9033|\n",
    "|0.9|0.1|0.9187|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec141b34",
   "metadata": {},
   "source": [
    "From the table above, the training size and the accuracy are directly proportional."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e491b50",
   "metadata": {},
   "source": [
    "#### Misclassified Posts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf46fe2",
   "metadata": {},
   "source": [
    "The result with the training size of 0.9 represents that there are still about 30 percent of misclassified texts. In every experiment, examining the misclassified data is essential for further inquiry. Thus, this step is for finding a few misclassified texts, determining if the predicted probabilities are excessively far off, and analyzing what make them to be incorrectly sorted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1068,
   "id": "fb1efe9a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('talk.religion.misc', 'alt.atheism', 3),\n",
       " ('talk.religion.misc', 'alt.atheism', 6),\n",
       " ('talk.religion.misc', 'alt.atheism', 12),\n",
       " ('talk.religion.misc', 'alt.atheism', 14),\n",
       " ('rec.autos', 'alt.atheism', 25),\n",
       " ('rec.autos', 'sci.electronics', 88),\n",
       " ('talk.religion.misc', 'alt.atheism', 102),\n",
       " ('rec.motorcycles', 'rec.autos', 123),\n",
       " ('rec.autos', 'alt.atheism', 127),\n",
       " ('talk.religion.misc', 'alt.atheism', 138)]"
      ]
     },
     "execution_count": 1068,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show 10 misclassified post\n",
    "misclassified_post = []\n",
    "for i, tf in enumerate(newsTF_result):\n",
    "    if tf != True:\n",
    "        misclassified_post.append((data_test.values[i][0], news_pred.values[i], i))\n",
    "# The returned list represents (Original, Predicted, post number)\n",
    "misclassified_post[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a803b8d",
   "metadata": {},
   "source": [
    "##### Any Reason?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97f188a",
   "metadata": {},
   "source": [
    "From 10 misclassified examples above, the classifier is confuesed of religion and atheism. Atheism is built upon disbelief in religious figures, which is the state between religious and agnostic. Even though atheism is against the belief in God, it still describes religious and philosophical concepts, which is certainly similar to religious post. Since the prior probabilites epxresses that the frequency of atheism is larger than that of religion, in the beginning of the classifying porcess, the classifier would have misunderstood the post and chosen atheism over religion."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "378853ed",
   "metadata": {},
   "source": [
    "### Stopwords Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1047,
   "id": "639b138c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the stopwords of Newsgroup Posts\n",
    "with open('stopwords.txt') as f:\n",
    "    stops = f.read()\n",
    "# Split the stopwords into a list of individual stopword\n",
    "stops = stops.split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1074,
   "id": "cd514ee5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 6640/6640 [00:01<00:00, 4384.63it/s]\n"
     ]
    }
   ],
   "source": [
    "# Remove Stopwords of each post of training set\n",
    "for data in tqdm(data_train['Body'].values):\n",
    "    data = [ele for ele in data if ele not in stops]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1073,
   "id": "f4289c8c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7321    [comes, indirectly, from, al, morgani, who, wo...\n",
       "3420    [tall, cool, one, rky57514, uxacsouiucedu, wro...\n",
       "3531    [andy, collins, acollins, uclinkberkeleyedu, w...\n",
       "2812    [i, hope, that, this, comes, off, as, a, somew...\n",
       "3913    [reading, all, you, folks, things, to, do, to,...\n",
       "                              ...                        \n",
       "905     [they, detect, the, oscillator, operating, in,...\n",
       "5192    [in, article, 1993apr1220105620753, ns1cclehig...\n",
       "3980    [in, article, apr1621515128035, engrwashington...\n",
       "235     [in, article, 1993apr617033012314, ismorgancom...\n",
       "5157    [anybody, got, any, goodbad, experience, with,...\n",
       "Name: Body, Length: 6640, dtype: object"
      ]
     },
     "execution_count": 1073,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preprocessed 'Body' after Stopwords Removal\n",
    "data_train['Body']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1050,
   "id": "835804b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply classifying method on posts of testing dataset after Removing Stopwords\n",
    "news_pred_stop = data_test['Body'].apply(classify_post_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1051,
   "id": "88e21b68",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5748       rec.motorcycles\n",
       "4875           alt.atheism\n",
       "4537       sci.electronics\n",
       "5857           alt.atheism\n",
       "6721    rec.sport.baseball\n",
       "               ...        \n",
       "4980       rec.motorcycles\n",
       "6556               sci.med\n",
       "1282       sci.electronics\n",
       "2921               sci.med\n",
       "3979       sci.electronics\n",
       "Name: Body, Length: 738, dtype: object"
      ]
     },
     "execution_count": 1051,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The result predicted by classifier after Removing Stopwords\n",
    "news_pred_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1076,
   "id": "d42b15d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9186991869918699"
      ]
     },
     "execution_count": 1076,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare the predicted result after stopwrods removal to the original\n",
    "newsTF_result_stop = (news_pred_stop == data_test['Newsgroup'])\n",
    "# Calculate the accuracy\n",
    "news_acc_09_stop = newsTF_result_stop.sum() / len(data_test['Newsgroup'])\n",
    "news_acc_09_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1075,
   "id": "a77f0877",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('talk.religion.misc', 'alt.atheism', 3),\n",
       " ('talk.religion.misc', 'alt.atheism', 6),\n",
       " ('talk.religion.misc', 'alt.atheism', 12),\n",
       " ('talk.religion.misc', 'alt.atheism', 14),\n",
       " ('rec.autos', 'alt.atheism', 25),\n",
       " ('rec.autos', 'sci.electronics', 88),\n",
       " ('talk.religion.misc', 'alt.atheism', 102),\n",
       " ('rec.motorcycles', 'rec.autos', 123),\n",
       " ('rec.autos', 'alt.atheism', 127),\n",
       " ('talk.religion.misc', 'alt.atheism', 138)]"
      ]
     },
     "execution_count": 1075,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List for misclassified post after stopwords removal\n",
    "misclassified_post_stop = []\n",
    "for i, tf in enumerate(newsTF_result_stop):\n",
    "    if tf != True:\n",
    "        misclassified_post_stop.append((data_test.values[i][0], news_pred_stop.values[i], i))\n",
    "# (Original Newsgroup, Predicted Newsgroup, misclassified post number)\n",
    "misclassified_post_stop[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cbbf206",
   "metadata": {},
   "source": [
    "Based on the results above, the accuracy has not changed, impling that the stopwords removal does not affect much on the subjects of the posts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c59566",
   "metadata": {},
   "source": [
    "Since the newsgroup posts usually consist of their specific words that are more related to their own topics, the stopwords would take large portion of the words the posts have in common. Hence, the stopwords removal might have affected the accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02bd2f9b",
   "metadata": {},
   "source": [
    "In addition to the investigation on newsgroup, the second part of this project is analyzing Naive Bayes Classifier on movie reviews dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e85e62",
   "metadata": {},
   "source": [
    "## Part 2. Movie Reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec69906",
   "metadata": {},
   "source": [
    "The first step is Load the Data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1539f337",
   "metadata": {},
   "source": [
    "### Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "eedd9319",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load movie_reviews.zip\n",
    "movies = pd.read_csv(\"movie_reviews.zip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff1c183",
   "metadata": {},
   "source": [
    "For movie revies, steps of preporcessing the dataset and spliting the dataset into training and testing are bundeled together."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1101ebbf",
   "metadata": {},
   "source": [
    "### Preprocess the Data and Split into Training and Testing Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c4c9bc",
   "metadata": {},
   "source": [
    "Training and testing sets are divided, and the data is preprocessed by removing useless strings and spaces. After that, the arrays are created to distinguish negative and positive reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1077,
   "id": "ecdeab44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████| 22500/22500 [00:01<00:00, 19042.11it/s]\n"
     ]
    }
   ],
   "source": [
    "# List for negative words\n",
    "neg = []\n",
    "# List for positive words\n",
    "pos = []\n",
    "# Spliting the dataset into training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(movies['review'], \n",
    "                                                    movies['sentiment'], \n",
    "                                                    test_size=0.1, \n",
    "                                                    random_state=1)\n",
    "# The length of training dataset\n",
    "n = len(X_train)\n",
    "# Loop through the length of training dataset\n",
    "for i in tqdm(range(len(X_train))):\n",
    "# Lowercase all reviews\n",
    "    words = movies.loc[i,'review'].lower()\n",
    "# Remove the bad strings of reviews\n",
    "    words = clean_string(words)   \n",
    "# Split the reviews into a list of individual words\n",
    "    words = words.split(' ')\n",
    "# If the sentiment of review is \"negative\"\n",
    "    if movies.loc[i,'sentiment'] == \"negative\":\n",
    "# Add word to neg\n",
    "        neg += words\n",
    "# If \"positive\"\n",
    "    else:\n",
    "# Add word to pos\n",
    "        pos += words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3f4809",
   "metadata": {},
   "source": [
    "With the sorted arrays from the above code, new dataframe is created with two columns of \"Negative\" and \"Positive\". Then, for each word, the dataframe has the record of its word counts in each type of review. Now, to find the probability of each review and classify its setiment, naive bayes is calculated; however, instead of $P(y|x)$, $log(P(y|x))$ is used in order to avoid underflow errors. Then, for the calculation of $log$, $1$ is added to all word counts since the word with word count $0$ would have $log(0)$, and $log(0)$ is mathematically undefined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "58b089ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change neg to Counter to count the frequency of each word in the negative reviews\n",
    "negCount = Counter(neg)\n",
    "# Change pos to Counter to count the frequency of each word in the positive reviews\n",
    "posCount = Counter(pos)\n",
    "# make new dictionary containing negative counts and positive counts\n",
    "movie_words_data = {\"Negative\":negCount,\"Positive\":posCount}\n",
    "# change the dictionary to dataframe; fill missing values with 0, and convert all values to int\n",
    "wc = pd.DataFrame(movie_words_data).fillna(0).astype(int)\n",
    "wc = wc + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0392c39a",
   "metadata": {},
   "source": [
    "### Implement the Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a4203d1",
   "metadata": {},
   "source": [
    "After preprocessing the data, the negative and positive probability of each review is calculated, and the larger number determines the sentiment of the review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1085,
   "id": "99f279f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# New empty array to represent no stopwords\n",
    "stops = []\n",
    "def rev_probs(review_text):\n",
    "# List to store the probability values for negative\n",
    "    neg_list = []\n",
    "# List to store the probability values for positive\n",
    "    pos_list = []\n",
    "# Preprocess the review text by cleaning it, converting it to lowercase, and splitting it into words\n",
    "    words = clean_string(review_text).lower().split(' ')\n",
    "# Loop through each word in the list\n",
    "    for word in words:\n",
    "# If each word is in the stopwords\n",
    "        if word in stops:\n",
    "# If it is, skip to the next word\n",
    "            None\n",
    "# If not\n",
    "        else:\n",
    "# Try to calculate the probabilities for the current word\n",
    "            try:\n",
    "# Calculate the probability of the word given each class (negative and positive)\n",
    "                p = wc.loc[word]/wc.sum()\n",
    "# Append the calculated probabilities to the corresponding lists\n",
    "                neg_list.append(p[\"Negative\"])\n",
    "                pos_list.append(p[\"Positive\"])\n",
    "# If an exception occurs, skip to the next word\n",
    "            except:\n",
    "                None\n",
    "# Total count of words in the DataFrame\n",
    "    total = np.array(wc.sum()).sum()\n",
    "# Initialize an array of ones with length of 2\n",
    "    prod = np.ones(2)\n",
    "# Calculate the prior probabilities for each class\n",
    "    prod[0] = wc['Negative'].sum()/(total)\n",
    "    prod[1] = wc['Positive'].sum()/(total)\n",
    "# Take the log10 of the probabilities\n",
    "    prod = np.log10(prod)\n",
    "# Add the log10 of the word probabilities for each class to the corresponding prior probabilities\n",
    "    prod[0] += np.log10(neg_list).sum()\n",
    "    prod[1] += np.log10(pos_list).sum()\n",
    "# Final log10 probabilities for the negative and positive classes\n",
    "    return prod\n",
    "\n",
    "def pre_sentiment(review):\n",
    "# Calculate probabilities of the review being negative or positive\n",
    "    prod = rev_probs(review)\n",
    "# Compare probabilities and return negative or positive\n",
    "    return 'negative' if prod[0] > prod[1] else 'positive'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1086,
   "id": "e29cb60f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 2500/2500 [02:42<00:00, 15.41it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " ...]"
      ]
     },
     "execution_count": 1086,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Empty list to store sentiment predictions for each review in the test dataset\n",
    "sentiment_predictions = []\n",
    "# Loop through each review in the test dataset\n",
    "for review in tqdm(X_test.values):\n",
    "# Predict the sentiment of current review using pre_sentiment function\n",
    "    prediction = pre_sentiment(review)\n",
    "# Append the predicted sentiment to the sentiment_predictions list\n",
    "    sentiment_predictions.append(prediction)\n",
    "# Return the list of sentiment predictions for all reviews in the test dataset\n",
    "sentiment_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a91c3355",
   "metadata": {},
   "source": [
    "Using the methods above, the array of predicted sentiments are created."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7dff7d",
   "metadata": {},
   "source": [
    "### Evaluate the Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "593824f6",
   "metadata": {},
   "source": [
    "The code below calculates the accuracy of the classifier when the training size is 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1087,
   "id": "833d677e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9228"
      ]
     },
     "execution_count": 1087,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare the predicted result to the original\n",
    "movieTF_result = (sentiment_predictions == y_test.values)\n",
    "# Calculate the accuracy\n",
    "acc_09 = (movieTF_result).sum() / len(y_test.values)\n",
    "acc_09"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c22119a2",
   "metadata": {},
   "source": [
    "#### Does the Size of Training Set Matters?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5744778",
   "metadata": {},
   "source": [
    "Using the codes above, by adjusting the size of testing set from the part of preprocessing the data, the investigation is led in order to study if the sizes of training set and testing set matter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6bee00",
   "metadata": {},
   "source": [
    "|Train Size|Test Size|Accuracy|\n",
    "|-|-|-|\n",
    "|0.1|0.9|0.8379|\n",
    "|0.3|0.7|0.8764|\n",
    "|0.5|0.5|0.8962|\n",
    "|0.7|0.3|0.9059|\n",
    "|0.9|0.1|0.9084|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c24a04",
   "metadata": {},
   "source": [
    "From the table above, the training size and the accuracy are directly proportional. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932be8f3",
   "metadata": {},
   "source": [
    "#### Misclassified Texts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a17cb1",
   "metadata": {},
   "source": [
    "The result with the training size of 0.9 represents that there are still about 0.27 amount of misclassified texts. In every experiment, examining the misclassified data is essential for further inquiry. Thus, this step is for finding a few misclassified texts, determining if the predicted probabilities are excessively far off, and analyzing what make them to be incorrectly sorted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1088,
   "id": "77faaa2e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(\"In my years of attending film festivals, I have seen many little films like this that never get theatrical distribution, and they end up in the $3 bins at WalMart. I just found DVD of Yank Tanks there, great doc, but how sad for it to end up as a rock-bottom remainder.<br /><br />I loved this film, wish I'd seen it at the cinema in it's everything. I'd have preferred that New Yorker Films had translated the title directly. It's good for Americans to stretch a little. If the film's title helps the US audience to explore random chaos, all the better. Cinema imitates life & visa versa.<br /><br />Also, I found it distracting that the subtitles put prices in dollars. Come on! The euro is not hard to figure out, make the gringo audiences do the math. Seeing a film, especially one shot in Paris, the viewer should not have the effect spoiled by being reminded: I am an American watching a movie and they are translating the Euros into dollars for me. <br /><br />Looking forward to seeing more of these actors and more from the writer & director as well.\",\n",
       "  'positive',\n",
       "  'negative',\n",
       "  10),\n",
       " ('Rich ditzy Joan Winfield (a woefully miscast Bette Davis) is engaged to be married to stupid egotistical Allen Brice (Jack Carson looking lost). Her father (Eugene Palette) is determined to stop the marriage and has her kidnapped by pilot Steve Collins (James Cagney. Seriously). They crash land in the desert and hate each other but (sigh) start falling in love.<br /><br />This seems to be getting a high rating from reviewers here only because Cagney and Davis are in it. They were both brilliant actors but they were known for dramas NOT comedy and this movie shows why! The script is just horrible--there\\'s not one genuine laugh in the entire movie. The running joke in this has Cagney and Davis falling rump first in a cactus (this is done THREE TIMES!). Only their considerable talents save them from being completely humiliated. As it is they both do their best with the lousy material. Cagney tries his best with his lines and Davis screeches every line full force but it doesn\\'t work. Carson has this \"what the hell\" look on his face throughout the entire movie (probably because his characters emotions change in seconds). Only Palette with his distinctive voice and over the top readings manges to elicit a few smiles. But, all in all, this was dull and laughless--a real chore to sit through. This gets two stars only for Cagney and Davis\\' acting and some beautiful cinematography but really--it\\'s not worth seeing. Cagney and Davis hated this film in later years and you can see why.',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  11),\n",
       " ('There are a few spoilers in this comment!!<br /><br />Contrary to the comments I just read by nativetex4u and a few others, I really liked the movie and would love to see it as a weekly series.<br /><br />I am a Judson Mills fan but also a huge Chuck Norris fan and while I\\'ll admit that a few of the action scenes may have stretched the line a little, the storyline fit right in with other weekly series that are currently being aired.<br /><br />The opening fifteen minutes with Deke running from the bad guys after blowing up their missiles was very action packed. I do fail to see how that many \"professionals\" weren\\'t able to hit a moving target, but the action was definitely there and Deke, being the hero, had to survive.<br /><br />As for the comment about needing to \"get the movie in the can to fill the time slot after the playoffs.\" This movie was not originally scheduled by CBS for a January airing and filming was completed in May of 2001, a good 4 months before the terrorist attacks against the U.S.<br /><br />If the writer of the comment had been paying attention to the movie instead of trying to avoid it, maybe they would have realized the plot of the story: Rashid, a Bin Laden like character, planned to set off a nuclear device in the United States. The President\\'s Man was called in to locate and eliminate the problem.<br /><br />Perhaps the writer should actually WATCH the movie before attempting to comment on it.<br /><br />',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  29),\n",
       " (\"The acting, other reviews notwithstanding, was remarkably well-done. Brad Pitt handles the role of an annoying, obnoxious Austrian climber quite well. Other acting is fine. The story could have been riveting, but somehow, it misses - one never really understands or cares for the characters shown, and so the story, which could have been quite dramatic, fails to draw in this audience.<br /><br />Beautiful scenery and cinematography, a remarkably dramatic true story, important events that shaped the world that we live in - but I could not, try as I might, involve myself in this story. As an unabashed Brad Pitt fan (I consider him one of the top 5 actors of his generation), I expected to *love* this flick - and yet, it left me cold.<br /><br />It could be a failing within myself, but I tend to point toward the creative end of this movie - direction, scriptwriting, production, editing - somehow, they lost me. It's a shame, because it could have been wonderful.<br /><br />Good acting, dramatic story, beautifully shot - it should have been magnificent. It wasn't. Probably worth watching, just to make your own mind up on it - but don't expect too much, and perhaps you won't be as disappointed as I was. Mostly, it bored me.\",\n",
       "  'negative',\n",
       "  'positive',\n",
       "  32),\n",
       " (\"Yes, CHUNKY, this is the nick-name that Donna Reeds' romantic lead played by Tom Drake tags her with! So lets get this clear right away. From her first ingénue role in THE GET-AWAY (1941) too her last, DALLAS (1984-1985) Ms. Reed could NEVER be described as CHUNKY. Not this attractive and slim actress. Whose roles at M.G.M. seldom lived up to her talents.<br /><br />Ms. Reed is supported by a cast of competent character actors, who unfortunately must flounder through this alleged 'screw-ball' comedy. Clearly M.G.M. was out of their depth making this type of film. A type better produced over at COLUMBIA, PARAMOUNT, RKO and even UNIVERSAL. Neither the 'touch' of Ernst Lubitsch nor the wit of Preston Sturges could save this film. A rather conventional romantic comedy that had all the markings of a pre-war (WWII) effort.<br /><br />If Irving Thalberg had still been alive the screen-play would have either gone through a significant rewrite or never seen the light of day. It did fit into Louis B. Mayer's 'safe-zone' of none challenging family entertainment. A form that could not stand up to the post-war challenges of the 'DeHavilland Decision', loss of their theater chains, television and would contribute to M.G.M.s decline. Fortunetly for Donna Reed her best days are ahead of her culminating in FROM HERE TO ETERNITY (1953) and her Oscar win as Best Supporting Actress.\",\n",
       "  'negative',\n",
       "  'positive',\n",
       "  36)]"
      ]
     },
     "execution_count": 1088,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show 5 misclassified reviews\n",
    "misclassified = []\n",
    "# Loop through the compared result\n",
    "for i, tf in enumerate(movieTF_result):\n",
    "# If not True\n",
    "    if tf != True:\n",
    "        misclassified.append((X_test.values[i], y_test.values[i], sentiment_predictions[i], i))\n",
    "# The returned list represents (Movie Review, Original Sentiment, Predicted Sentiment, Review Number)\n",
    "misclassified[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc3e2ff",
   "metadata": {},
   "source": [
    "##### Probabilites of Misclassified Texts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e467ef",
   "metadata": {},
   "source": [
    "The previous part produces the 2D array of misclassified texts and their original setiments. From the 2D array, 5 examples are chosen for the calculation of probabilites of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1089,
   "id": "214344ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 misclassified texts\n",
    "misclassified_ex = misclassified[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1090,
   "id": "12bbb857",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-388.90915935, -389.16376262])"
      ]
     },
     "execution_count": 1090,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The probabilities of misclassified text\n",
    "mis_prob0 = rev_probs(misclassified_ex[0][0])\n",
    "# Print Review Number\n",
    "print(misclassified_ex[0][3])\n",
    "mis_prob0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ced96c",
   "metadata": {},
   "source": [
    "For the first example, the predicted setiment is negative, but the original is positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1091,
   "id": "a6f26343",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-568.57661636, -564.51750241])"
      ]
     },
     "execution_count": 1091,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mis_prob1 = rev_probs(misclassified_ex[1][0])\n",
    "print(misclassified_ex[1][3])\n",
    "mis_prob1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9335ff4",
   "metadata": {},
   "source": [
    "For the second example, the predicted setiment is negative, but the original is positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1092,
   "id": "b7cc505a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-481.48140245, -483.79963026])"
      ]
     },
     "execution_count": 1092,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mis_prob2 = rev_probs(misclassified_ex[2][0])\n",
    "print(misclassified_ex[2][3])\n",
    "mis_prob2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c99bf30",
   "metadata": {},
   "source": [
    "For the third example, the predicted setiment is positive, but the original is negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1093,
   "id": "63038f08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-397.69439777, -397.03839223])"
      ]
     },
     "execution_count": 1093,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mis_prob3 = rev_probs(misclassified_ex[3][0])\n",
    "print(misclassified_ex[3][3])\n",
    "mis_prob3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053e6692",
   "metadata": {},
   "source": [
    "For the forth example, the predicted setiment is negative, but the original is positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1094,
   "id": "750f28e4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-579.13246099, -577.66518058])"
      ]
     },
     "execution_count": 1094,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mis_prob4 = rev_probs(misclassified_ex[4][0])\n",
    "print(misclassified_ex[4][3])\n",
    "mis_prob4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18fb534d",
   "metadata": {},
   "source": [
    "For the last example, the predicted setiment is negative, but the original is positive."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c003a819",
   "metadata": {},
   "source": [
    "##### Any Reason?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8bb5d0e",
   "metadata": {},
   "source": [
    "For all 5 missorted examples, the negative and positive probabilites are exremely close. In order to reducdes the misclassified texts with those reasons, the classifier needs to be analyzed. Analyzing can help identify potential issues or areas for improvement in the classifier, so the first approach is removing the stopwords."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0acb6d9c",
   "metadata": {},
   "source": [
    "### Stopwords Removal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a3fc5b",
   "metadata": {},
   "source": [
    "The first part of stopwords removal is loading the data of stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1095,
   "id": "daee5472",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the stopwords of Movie Reviews\n",
    "with open('stopwords.txt') as f:\n",
    "    stops = f.read()\n",
    "# items to be removed\n",
    "stops = stops.split(',')\n",
    "wc = wc.drop(stops, errors='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1adc4bad",
   "metadata": {},
   "source": [
    "Then, the naive bayes classifier is implemented, and this process includes removing the stopwords in each review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1096,
   "id": "78fd5196",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 2500/2500 [02:44<00:00, 15.22it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " ...]"
      ]
     },
     "execution_count": 1096,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Empty list to store sentiment predictions after stopwords removal for each review in the test dataset\n",
    "sentiment_pred_stopwords = []\n",
    "# Loop through each review in the test dataset\n",
    "for review in tqdm(X_test.values):\n",
    "# Predict the sentiment of the current review after removing stopwords\n",
    "    prediction = pre_sentiment(review)\n",
    "# Append the predicted sentiment after stopwords removal to the sentiment_predictions list\n",
    "    sentiment_pred_stopwords.append(prediction)\n",
    "# List of sentiment predictions after stopwords removal for all reviews in the test dataset\n",
    "sentiment_pred_stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7351ab41",
   "metadata": {},
   "source": [
    "Following code calculates the accuracy of the classifier after removing stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1097,
   "id": "42a1efe8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9228"
      ]
     },
     "execution_count": 1097,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movieTF_stopwords_result = (sentiment_pred_stopwords == y_test.values)\n",
    "acc_09_stopwords = (movieTF_stopwords_result).sum() / len(y_test.values)\n",
    "acc_09_stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d4d642",
   "metadata": {},
   "source": [
    "After removing stopwords, the classifier was run, and the accuracy increased by approximately 0.0144."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "9f4297b6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(\"In my years of attending film festivals, I have seen many little films like this that never get theatrical distribution, and they end up in the $3 bins at WalMart. I just found DVD of Yank Tanks there, great doc, but how sad for it to end up as a rock-bottom remainder.<br /><br />I loved this film, wish I'd seen it at the cinema in it's everything. I'd have preferred that New Yorker Films had translated the title directly. It's good for Americans to stretch a little. If the film's title helps the US audience to explore random chaos, all the better. Cinema imitates life & visa versa.<br /><br />Also, I found it distracting that the subtitles put prices in dollars. Come on! The euro is not hard to figure out, make the gringo audiences do the math. Seeing a film, especially one shot in Paris, the viewer should not have the effect spoiled by being reminded: I am an American watching a movie and they are translating the Euros into dollars for me. <br /><br />Looking forward to seeing more of these actors and more from the writer & director as well.\",\n",
       "  'positive',\n",
       "  'negative',\n",
       "  10),\n",
       " ('Rich ditzy Joan Winfield (a woefully miscast Bette Davis) is engaged to be married to stupid egotistical Allen Brice (Jack Carson looking lost). Her father (Eugene Palette) is determined to stop the marriage and has her kidnapped by pilot Steve Collins (James Cagney. Seriously). They crash land in the desert and hate each other but (sigh) start falling in love.<br /><br />This seems to be getting a high rating from reviewers here only because Cagney and Davis are in it. They were both brilliant actors but they were known for dramas NOT comedy and this movie shows why! The script is just horrible--there\\'s not one genuine laugh in the entire movie. The running joke in this has Cagney and Davis falling rump first in a cactus (this is done THREE TIMES!). Only their considerable talents save them from being completely humiliated. As it is they both do their best with the lousy material. Cagney tries his best with his lines and Davis screeches every line full force but it doesn\\'t work. Carson has this \"what the hell\" look on his face throughout the entire movie (probably because his characters emotions change in seconds). Only Palette with his distinctive voice and over the top readings manges to elicit a few smiles. But, all in all, this was dull and laughless--a real chore to sit through. This gets two stars only for Cagney and Davis\\' acting and some beautiful cinematography but really--it\\'s not worth seeing. Cagney and Davis hated this film in later years and you can see why.',\n",
       "  'negative',\n",
       "  'positive',\n",
       "  11),\n",
       " ('There are a few spoilers in this comment!!<br /><br />Contrary to the comments I just read by nativetex4u and a few others, I really liked the movie and would love to see it as a weekly series.<br /><br />I am a Judson Mills fan but also a huge Chuck Norris fan and while I\\'ll admit that a few of the action scenes may have stretched the line a little, the storyline fit right in with other weekly series that are currently being aired.<br /><br />The opening fifteen minutes with Deke running from the bad guys after blowing up their missiles was very action packed. I do fail to see how that many \"professionals\" weren\\'t able to hit a moving target, but the action was definitely there and Deke, being the hero, had to survive.<br /><br />As for the comment about needing to \"get the movie in the can to fill the time slot after the playoffs.\" This movie was not originally scheduled by CBS for a January airing and filming was completed in May of 2001, a good 4 months before the terrorist attacks against the U.S.<br /><br />If the writer of the comment had been paying attention to the movie instead of trying to avoid it, maybe they would have realized the plot of the story: Rashid, a Bin Laden like character, planned to set off a nuclear device in the United States. The President\\'s Man was called in to locate and eliminate the problem.<br /><br />Perhaps the writer should actually WATCH the movie before attempting to comment on it.<br /><br />',\n",
       "  'positive',\n",
       "  'negative',\n",
       "  29),\n",
       " (\"The acting, other reviews notwithstanding, was remarkably well-done. Brad Pitt handles the role of an annoying, obnoxious Austrian climber quite well. Other acting is fine. The story could have been riveting, but somehow, it misses - one never really understands or cares for the characters shown, and so the story, which could have been quite dramatic, fails to draw in this audience.<br /><br />Beautiful scenery and cinematography, a remarkably dramatic true story, important events that shaped the world that we live in - but I could not, try as I might, involve myself in this story. As an unabashed Brad Pitt fan (I consider him one of the top 5 actors of his generation), I expected to *love* this flick - and yet, it left me cold.<br /><br />It could be a failing within myself, but I tend to point toward the creative end of this movie - direction, scriptwriting, production, editing - somehow, they lost me. It's a shame, because it could have been wonderful.<br /><br />Good acting, dramatic story, beautifully shot - it should have been magnificent. It wasn't. Probably worth watching, just to make your own mind up on it - but don't expect too much, and perhaps you won't be as disappointed as I was. Mostly, it bored me.\",\n",
       "  'negative',\n",
       "  'positive',\n",
       "  32),\n",
       " (\"Yes, CHUNKY, this is the nick-name that Donna Reeds' romantic lead played by Tom Drake tags her with! So lets get this clear right away. From her first ingénue role in THE GET-AWAY (1941) too her last, DALLAS (1984-1985) Ms. Reed could NEVER be described as CHUNKY. Not this attractive and slim actress. Whose roles at M.G.M. seldom lived up to her talents.<br /><br />Ms. Reed is supported by a cast of competent character actors, who unfortunately must flounder through this alleged 'screw-ball' comedy. Clearly M.G.M. was out of their depth making this type of film. A type better produced over at COLUMBIA, PARAMOUNT, RKO and even UNIVERSAL. Neither the 'touch' of Ernst Lubitsch nor the wit of Preston Sturges could save this film. A rather conventional romantic comedy that had all the markings of a pre-war (WWII) effort.<br /><br />If Irving Thalberg had still been alive the screen-play would have either gone through a significant rewrite or never seen the light of day. It did fit into Louis B. Mayer's 'safe-zone' of none challenging family entertainment. A form that could not stand up to the post-war challenges of the 'DeHavilland Decision', loss of their theater chains, television and would contribute to M.G.M.s decline. Fortunetly for Donna Reed her best days are ahead of her culminating in FROM HERE TO ETERNITY (1953) and her Oscar win as Best Supporting Actress.\",\n",
       "  'negative',\n",
       "  'positive',\n",
       "  36)]"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show 5 misclassified reviews after stopwords removal\n",
    "misclassified_stopwords = []\n",
    "# Loop through the results after removing stopwors\n",
    "for i, tf in enumerate(movieTF_stopwords_result):\n",
    "# If not True\n",
    "    if tf != True:\n",
    "        misclassified_stopwords.append((X_test.values[i], y_test.values[i], sentiment_pred_stopwords[i], i))\n",
    "# The returned list represents (Movie Review, Original Sentiment, Predicted Sentiment, Review Number)\n",
    "misclassified_stopwords[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "40763511",
   "metadata": {},
   "outputs": [],
   "source": [
    "misclassified_stopwords_ex = misclassified_stopwords[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "19b2287b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-388.90915935, -389.16376262])"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mis_prob0_stop = rev_probs(misclassified_stopwords_ex[0][0])\n",
    "print(misclassified_stopwords_ex[0][3])\n",
    "mis_prob0_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "ef5c600e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-568.57661636, -564.51750241])"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mis_prob1_stop = rev_probs(misclassified_stopwords_ex[1][0])\n",
    "print(misclassified_stopwords_ex[1][3])\n",
    "mis_prob1_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "a9f018c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-481.48140245, -483.79963026])"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mis_prob2_stop = rev_probs(misclassified_stopwords_ex[2][0])\n",
    "print(misclassified_stopwords_ex[2][3])\n",
    "mis_prob2_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "d61f5077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-397.69439777, -397.03839223])"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mis_prob3_stop = rev_probs(misclassified_stopwords_ex[3][0])\n",
    "print(misclassified_stopwords_ex[3][3])\n",
    "mis_prob3_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "c139e8fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-579.13246099, -577.66518058])"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mis_prob4_stop = rev_probs(misclassified_stopwords_ex[4][0])\n",
    "print(misclassified_stopwords_ex[4][3])\n",
    "mis_prob4_stop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54cb5a2a",
   "metadata": {},
   "source": [
    "With the stopwords removal, a few of the misclassified texts have been correctly sorted. In case of 10th and 11th texts, they are still misclassified; however, the differences between their negative and positive probabilites have been decreased, which means that the classifier has been improved. The next approach for improvement is using negations. The negations can change the meaning of words and phrases, and it is significant for the classifier to understand them. Thus, by adding prefix \"NOT_\" in front of the negations words, such as \"not\" and \"isn't\", the classifier may be improved."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c58d1d8",
   "metadata": {},
   "source": [
    "### Text Samples with Negations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d370909",
   "metadata": {},
   "source": [
    "#### How Negations Can Change the Meaning of Words and Phrases? (Add \"NOT_\" in front of Negation Words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "a856c6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Representing negation words using Regular Expressions\n",
    "negation_words = r\"\\b\\w*(?:not|n't)\\b\"\n",
    "# Add prefix \"NOT_\" in front of all the negation words\n",
    "def add_NOT(match):\n",
    "    return \"NOT_\" + match.group()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "b91213b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 2500/2500 [02:36<00:00, 15.95it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " ...]"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Empty list to store sentiment predictions with negating negation words\n",
    "sentiment_pred_NOT = []\n",
    "for review in tqdm(X_test.values):\n",
    "    newReview = re.sub(negation_words, add_NOT, review, flags=re.IGNORECASE)\n",
    "    prediction = pre_sentiment(newReview)\n",
    "    sentiment_pred_NOT.append(prediction)\n",
    "sentiment_pred_NOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "c8413843",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9264"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movieTF_NOT_result = (sentiment_pred_NOT == y_test.values)\n",
    "acc_09_NOT = (movieTF_NOT_result).sum() / len(y_test.values)\n",
    "acc_09_NOT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6807df59",
   "metadata": {},
   "source": [
    "The result of adding prefix \"NOT_\" seems successful; the accuracy is increased by approximately 0.0036."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deef42e4",
   "metadata": {},
   "source": [
    "In addition to the result above, this adding prefix method is applied to new random texts containing several negation words in order to accurately clarify that adding \"NOT_\" is unsuccessful method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec109db9",
   "metadata": {},
   "source": [
    "### Applying Classifier to New Texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "4a705cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Positive text with Negation words in it\n",
    "text_NOT = \"This is not a bad process. There are't any bugs in my house.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "68c9e7ca",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'negative'"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Result without using negations\n",
    "pre_sentiment(text_NOT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217d1569",
   "metadata": {},
   "source": [
    "At the first time, even though the context of the \"text_NOT\" is not negative, the classifier labels the text as negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "0cfb9962",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'positive'"
      ]
     },
     "execution_count": 375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_text_NOT = re.sub(negation_words, add_NOT, review, flags=re.IGNORECASE)\n",
    "new_text_pred_NOT = pre_sentiment(new_text_NOT)\n",
    "# Result with using negations\n",
    "new_text_pred_NOT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "453e9d50",
   "metadata": {},
   "source": [
    "After going through adding \"NOT_\" prefix in front of all negation words, now the classifier correctly distinguishes the text as positive. Thus, it is proved that this method is appropriate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d15cfcba",
   "metadata": {},
   "source": [
    "### Most Frequent Words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1220ca37",
   "metadata": {},
   "source": [
    "As the last experiment on Movie Reviews, the code below produces five most frequent words for negative and positive reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "f588537b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Negative</th>\n",
       "      <th>Positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>movie</th>\n",
       "      <td>21367</td>\n",
       "      <td>16355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>film</th>\n",
       "      <td>16273</td>\n",
       "      <td>17780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>one</th>\n",
       "      <td>11435</td>\n",
       "      <td>11777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>8896</td>\n",
       "      <td>8594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>out</th>\n",
       "      <td>7985</td>\n",
       "      <td>7088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>it's</th>\n",
       "      <td>7549</td>\n",
       "      <td>7538</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Negative  Positive\n",
       "movie     21367     16355\n",
       "film      16273     17780\n",
       "one       11435     11777\n",
       "           8896      8594\n",
       "out        7985      7088\n",
       "it's       7549      7538"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Most Frequent words in the negative sentiment\n",
    "wc.sort_values(by=['Negative'], ascending=[False])[:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "82768d35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Negative</th>\n",
       "      <th>Positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>film</th>\n",
       "      <td>16273</td>\n",
       "      <td>17780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movie</th>\n",
       "      <td>21367</td>\n",
       "      <td>16355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>one</th>\n",
       "      <td>11435</td>\n",
       "      <td>11777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>8896</td>\n",
       "      <td>8594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>it's</th>\n",
       "      <td>7549</td>\n",
       "      <td>7538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>very</th>\n",
       "      <td>5129</td>\n",
       "      <td>7370</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Negative  Positive\n",
       "film      16273     17780\n",
       "movie     21367     16355\n",
       "one       11435     11777\n",
       "           8896      8594\n",
       "it's       7549      7538\n",
       "very       5129      7370"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Most Frequent words in the positiive sentiment\n",
    "wc.sort_values(by=['Positive'], ascending=[False])[:6]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b83468e",
   "metadata": {},
   "source": [
    "Negative and positive reviews have a few common most frequent words. Since they are all movie reveiws, they both contain the word \"movie\" and \"film\" the most, and as the word \"one\" specifies certain movies or characters the reviews talk about, all reviews contain the word \"one\" as the third most frequent word. Then, there is one difference between negative and positive reviews. While negative reviews have the word \"out\" the fourth most frequent word, positive reviews have the word \"very\" on its fifth most frequent word. Since the word \"very\" often has positive expressions, the negative reviews have less amounts of the word \"very\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "509c689a",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3045caa3",
   "metadata": {},
   "source": [
    "Overlal, this project have investigated the performance of the Naive Bayes classifier for text classification on two distinct datasets: (1) newsgroup posts and (2) movie reviews. This comprehensive study displays valuable insights into the strengths and limitations of the Naive Bayes classifier for various text classification tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cacfec1c",
   "metadata": {},
   "source": [
    "The analysis revealed that the classifier could effectively predict the sentiment of a movie review, and identify the newsgroup to which a post belongs. The impact of various factors on the classification accuracy, such as the size of the training set and the inclusion of stopwords are also explored. It was found that removing stopwords improved the performance of the classifier only on movie reviews, while increasing the size of the training set generally led to better classification accuracy for both datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd68eb6",
   "metadata": {},
   "source": [
    "By examining misclassified examples, we have gained insights into the limitations of the Naive Bayes classifier and the challenges it faces in certain cases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e43377",
   "metadata": {},
   "source": [
    "In conclusion, the Naive Bayes classifier has proven to be a valuable tool for text classification tasks. This study provides a strong foundation for future research and improvements. Exploring more sophisticated techniques to handle negations or investigating the performance of the Naive Bayes classifier will be supportive tool in combination with other machine learning algorithms. Ultimately, the findings from this project will contribute to the ongoing development of efficient and effective text classification systems for various applications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e68dc5d3",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de312927",
   "metadata": {},
   "source": [
    "1.9. naive Bayes. scikit. (n.d.). Retrieved April 23, 2023, from https://scikit-learn.org/stable/modules/naive_bayes.html#:~:text=Naive%20Bayes%20methods%20are%20a,value%20of%20the%20class%20variable "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
